{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51130d13",
   "metadata": {},
   "source": [
    "# Определение негативные комментариев\n",
    "\n",
    "Пользователи интернет магазина могут редактировать и дополнять описания товаров. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2d92f3",
   "metadata": {},
   "source": [
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле toxic_comments.csv.\n",
    "\n",
    "Столбец text в нём содержит текст комментария, столбец toxic — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f571f8",
   "metadata": {},
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641048f",
   "metadata": {},
   "source": [
    "### 0. подключение библиотек, задание констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22da53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno 8] nodename nor servname provided, or not\n",
      "[nltk_data]     known>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score, f1_score\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_sw\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob, Word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05069a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08080d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e8c04bd",
   "metadata": {},
   "source": [
    "### 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f3af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '/Users/dmitry/Desktop/yandex_python/12. Машинное обучение для текстов/toxic_comments.csv'\n",
    "path2 = '/datasets/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(path1):\n",
    "    data = pd.read_csv(path1)\n",
    "elif os.path.exists(path2):\n",
    "    data = pd.read_csv(path2)\n",
    "else:\n",
    "    print('file not found')\n",
    "\n",
    "#data['text'] = data['text'].values.astype('U') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9845f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df8f072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32b419e",
   "metadata": {},
   "source": [
    "удалим лишний столбец \"Unnamed: 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe64212",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 0', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60083937",
   "metadata": {},
   "source": [
    "Посмотрим кол-во дубликатов, пропусков и долю негативных комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7934bd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кол-во дубликатов \t\t 0\n",
      "кол-во пропусков \"text\" \t 0\n",
      "кол-во пропусков \"toxic\"\t 0\n",
      "доля негативных комментариев \t 10.2%\n"
     ]
    }
   ],
   "source": [
    "print('кол-во дубликатов \\t\\t', data['text'].duplicated().sum())\n",
    "print('кол-во пропусков \"text\" \\t', data['text'].isna().sum())\n",
    "print('кол-во пропусков \"toxic\"\\t', data['toxic'].isna().sum())\n",
    "\n",
    "share_neg_com = data['toxic'].sum() / len(data)\n",
    "print(f'доля негативных комментариев \\t {100 * round(share_neg_com,3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23913001",
   "metadata": {},
   "source": [
    "#### Промежуточные выводы:\n",
    "1. Загружены данные, содержащие 159292 строки\n",
    "2. Дубликатов не обнаружено\n",
    "3. Пропусков не обнаружено\n",
    "4. Выборка не сбалансирована, содержит 10.2% негативных комментария\n",
    "5. Удален неинформативных столбец, дублирующий номера строк\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bababbf",
   "metadata": {},
   "source": [
    "#### Разобьём данные на тренировочную и тестовую выборки, выполнил предобработку данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e5da03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (95574, 2)\n",
      "valid: (31859, 2)\n",
      "test: (31859, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size = 0.2, random_state = rs) \n",
    "train, valid = train_test_split(train, test_size = 0.25, random_state = rs) \n",
    "\n",
    "print('train:', train.shape)\n",
    "print('valid:', valid.shape)\n",
    "print('test:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b8d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b52e5d7",
   "metadata": {},
   "source": [
    "предобработаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a1e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def lemmatize_with_postag(sentence):\n",
    "    sent = TextBlob(sentence)\n",
    "    tag_dict = {\"J\": 'a', \n",
    "                \"N\": 'n', \n",
    "                \"V\": 'v', \n",
    "                \"R\": 'r'}\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n",
    "    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
    "    return \" \".join(lemmatized_list)\n",
    "\n",
    "\n",
    "\n",
    "def clean_and_lem (df_lc, column):\n",
    "    \n",
    "    print(df_lc.shape)\n",
    "    df_lc = df_lc.copy()\n",
    "    \n",
    "    df_lc[column] = df_lc[column].apply(cleaning)\n",
    "    \n",
    "    #m = Mystem()\n",
    "    lemm_text = []\n",
    "    for text in tqdm(df_lc['text']):\n",
    "        lemm = lemmatize_with_postag(text)\n",
    "        lemm_text.append(\"\".join(lemm))\n",
    "        \n",
    "        #lemm = m.lemmatize(text)\n",
    "        #lemm_text.append(\"\".join(lemm))\n",
    "        \n",
    "    df_lc[f'lemm_{column}'] = lemm_text\n",
    "    df_lc = df_lc.drop('text', axis = 1)\n",
    "    \n",
    "    return df_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f99682a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697\n",
      "9697\n",
      "train_b: 19394\n"
     ]
    }
   ],
   "source": [
    "# нормализацию обучающей выборки закомментил, т.к. при её применении результаты метрики f1 для моделей ухудшаются\n",
    "# нормализуем обучающую выборку\n",
    "\n",
    "data_1 = train.loc[data['toxic'] == 1]\n",
    "data_0 = train.loc[data['toxic'] == 0]\n",
    "\n",
    "data_0 = shuffle(data_0).head(len(data_1))\n",
    "\n",
    "print(len(data_1))\n",
    "print(len(data_0))\n",
    "\n",
    "train_b = pd.concat([data_0, data_1])\n",
    "train_b = shuffle(train_b)\n",
    "print('train_b:', len(train_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "629b6da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95574, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 95574/95574 [03:56<00:00, 403.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31859, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 31859/31859 [01:17<00:00, 410.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19394, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 19394/19394 [00:43<00:00, 443.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31859, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 31859/31859 [01:17<00:00, 409.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train_lemm = clean_and_lem (train, 'text')\n",
    "test_lemm = clean_and_lem (test, 'text')\n",
    "train_b_lemm = clean_and_lem (train_b, 'text')\n",
    "valid_lemm = clean_and_lem (valid, 'text')\n",
    "\n",
    "t_train = train_lemm['toxic']\n",
    "f_train = train_lemm['lemm_text']\n",
    "\n",
    "t_test = test_lemm['toxic']\n",
    "f_test = test_lemm['lemm_text']\n",
    "\n",
    "t_train_b = train_b_lemm['toxic']\n",
    "f_train_b = train_b_lemm['lemm_text']\n",
    "\n",
    "t_valid = valid_lemm['toxic']\n",
    "f_valid = valid_lemm['lemm_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf52f8a",
   "metadata": {},
   "source": [
    "выделим features и train для каждой части выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a89701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16581     shameful advert hi there i notice youre intere...\n",
       "146310    the left hand can anyone point to an article t...\n",
       "98430     please stop if you continue to delete or blank...\n",
       "19003     song move you give me some good advice about m...\n",
       "118084    i do not do that why be i suffering consequenc...\n",
       "Name: lemm_text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9ce952",
   "metadata": {},
   "source": [
    "удалим стопслова и векторизуем отзывы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f6fe1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(set(nltk_sw.words('english')))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "f_train_idf = count_tf_idf.fit_transform(f_train)\n",
    "f_test_idf = count_tf_idf.transform(f_test) \n",
    "f_train_b_idf = count_tf_idf.transform(f_train_b) \n",
    "f_valid_idf = count_tf_idf.transform(f_valid) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb769c3b",
   "metadata": {},
   "source": [
    "### 2. Обучение разных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24800403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_f1 (model_f, features, target):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    predict = model_f.predict(features)\n",
    "\n",
    "    t2 = time.time()\n",
    "    dt = t2-t1\n",
    "    f1 = f1_score(target, predict)\n",
    "    \n",
    "    #print('r2 =\\t', round(r2_score(target, predict),3))\n",
    "    print('f1 =\\t', round(f1,3))\n",
    "    print('время предсказания модели составило', round(dt,3),'сек\\n')\n",
    "    \n",
    "    return(round(f1,3), round(dt,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc811cef",
   "metadata": {},
   "source": [
    "#### Модель LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68e89bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 20, 'solver': 'saga'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "время обучения моделей составило:\n",
      "несбалансированная выборка:\t 136 сек\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'solver': 'lbfgs'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сбалансированная выборка:\t 49 сек\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_space = {'solver' : ['lbfgs', 'liblinear', 'saga'],\n",
    "              'C': [5,10,20]}\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000, random_state = rs)\n",
    "\n",
    "model_lr_opt = GridSearchCV(estimator=model,\n",
    "                            param_grid=grid_space,\n",
    "                            cv=5,\n",
    "                            scoring='f1'\n",
    "                           )\n",
    "model_b_lr_opt = model_lr_opt\n",
    "\n",
    "#обучение на несбалансированной выборке\n",
    "t1 = time.time()\n",
    "model_lr_opt.fit(f_train_idf, t_train)\n",
    "t2 = time.time()\n",
    "display(model_lr_opt.best_params_)\n",
    "dt_t_lr = round(t2-t1)\n",
    "print('время обучения моделей составило:')\n",
    "print('несбалансированная выборка:\\t', dt_t_lr,'сек\\n')\n",
    "\n",
    "\n",
    "#обучение на сбалансированной выборке\n",
    "t3 = time.time()\n",
    "model_b_lr_opt.fit(f_train_b_idf, t_train_b)\n",
    "t4 = time.time()\n",
    "display(model_lr_opt.best_params_)\n",
    "\n",
    "dt_t_lr_b = round(t4-t3)\n",
    "print('сбалансированная выборка:\\t', dt_t_lr_b, 'сек\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc2e00",
   "metadata": {},
   "source": [
    "для двух обученных моделей сравним значения f1, рассчитанные на несбалансированной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3178c3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "несбалансированная выборка\n",
      "f1 =\t 0.754\n",
      "время предсказания модели составило 0.005 сек\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression')\n",
    "print('несбалансированная выборка')\n",
    "C = model_lr_opt.best_params_['C']\n",
    "solver = model_lr_opt.best_params_['solver']\n",
    "\n",
    "model_lr = LogisticRegression(C=C, solver=solver, max_iter = 1000, random_state = rs)\n",
    "model_lr.fit(f_train_idf, t_train)\n",
    "f1_lr, dt_lr = model_f1 (model_lr, f_valid_idf, t_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "387b53e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "сбалансированная выборка\n",
      "f1 =\t 0.683\n",
      "время предсказания модели составило 0.002 сек\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression')\n",
    "print('сбалансированная выборка')\n",
    "C = model_b_lr_opt.best_params_['C']\n",
    "solver = model_b_lr_opt.best_params_['solver']\n",
    "\n",
    "model_b_lr = LogisticRegression(C=C, solver=solver, max_iter = 1000, random_state = rs)\n",
    "model_b_lr.fit(f_train_b_idf, t_train_b)\n",
    "f1_b_lr, dt_b_lr = model_f1 (model_b_lr, f_valid_idf, t_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339f660",
   "metadata": {},
   "source": [
    "#### Модель LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78b21d17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'n_estimators': 20, 'num_leaves': 20}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "время обучения моделей составило:\n",
      "несбалансированная выборка:\t 136 сек\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'n_estimators': 20, 'num_leaves': 20}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сбалансированная выборка:\t 25 сек\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_space = {\n",
    "              'n_estimators': [10,20],\n",
    "              'max_depth' : [5,10],\n",
    "              'num_leaves': [10,20]\n",
    "             }\n",
    "\n",
    "model = lgb.LGBMClassifier(random_state = rs, n_jobs = -1)\n",
    "\n",
    "model_lgb_opt = GridSearchCV(estimator=model,\n",
    "                             param_grid=grid_space,\n",
    "                             cv=5,\n",
    "                             scoring='f1'\n",
    "                            )\n",
    "model_b_lgb_opt = model_lgb_opt\n",
    "\n",
    "#обучение на несбалансированной выборке\n",
    "t1 = time.time()\n",
    "model_lgb_opt.fit(f_train_idf, t_train)\n",
    "t2 = time.time()\n",
    "\n",
    "display(model_lgb_opt.best_params_)\n",
    "dt_t_lgb = round(t2-t1)\n",
    "print('время обучения моделей составило:')\n",
    "print('несбалансированная выборка:\\t', dt_t_lr,'сек\\n')\n",
    "\n",
    "\n",
    "#обучение на сбалансированной выборке\n",
    "t3 = time.time()\n",
    "model_b_lgb_opt.fit(f_train_b_idf, t_train_b)\n",
    "t4 = time.time()\n",
    "display(model_b_lgb_opt.best_params_)\n",
    "\n",
    "dt_t_lgb_b = round(t4-t3)\n",
    "print('сбалансированная выборка:\\t', dt_t_lgb_b,'сек\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2d8db7",
   "metadata": {},
   "source": [
    "для двух обученных моделей сравним значения f1, рассчитанные на несбалансированной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c84ae081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier\n",
      "несбалансированная выборка\n",
      "f1 =\t 0.544\n",
      "время предсказания модели составило 0.067 сек\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LGBMClassifier')\n",
    "print('несбалансированная выборка')\n",
    "\n",
    "max_depth = model_lgb_opt.best_params_['max_depth']\n",
    "n_estimators = model_lgb_opt.best_params_['n_estimators']\n",
    "num_leaves = model_lgb_opt.best_params_['num_leaves']\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(max_depth=max_depth, n_estimators=n_estimators, num_leaves=num_leaves,\n",
    "                               random_state = rs, n_jobs = -1)\n",
    "\n",
    "model_lgb.fit(f_train_idf, t_train)\n",
    "f1_lgb, dt_lgb = model_f1 (model_lgb, f_valid_idf, t_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e71c9f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier\n",
      "сбалансированная выборка\n",
      "f1 =\t 0.633\n",
      "время предсказания модели составило 0.052 сек\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LGBMClassifier')\n",
    "print('сбалансированная выборка')\n",
    "\n",
    "max_depth = model_b_lgb_opt.best_params_['max_depth']\n",
    "n_estimators = model_b_lgb_opt.best_params_['n_estimators']\n",
    "num_leaves = model_b_lgb_opt.best_params_['num_leaves']\n",
    "\n",
    "model_b_lgb = lgb.LGBMClassifier(max_depth=max_depth, n_estimators=n_estimators, num_leaves=num_leaves,\n",
    "                                 random_state = rs, n_jobs = -1)\n",
    "\n",
    "model_b_lgb.fit(f_train_b_idf, t_train_b)\n",
    "f1_b_lgb, dt_b_lgb = model_f1 (model_b_lgb, f_valid_idf, t_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb9a567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99cca50f",
   "metadata": {},
   "source": [
    "#### Сравнение с константной моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d7ec80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат предсказания модели = toxic\n",
      "f1 =\t 0.186\n",
      "время предсказания модели составило 0.002 секунд\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#сравним с результатами модели, предсказывающей всем 1\n",
    "\n",
    "t1 = time.time()\n",
    " \n",
    "p_valid = list([1]*len(t_valid))\n",
    "    \n",
    "t2 = time.time()\n",
    "dt_dm_t = round(t2-t1,3)\n",
    "f1_dm_t = round(f1_score(t_valid, p_valid),3)\n",
    "\n",
    "print('Результат предсказания модели = toxic')\n",
    "#print('r2 =\\t', round(r2_score(t_valid, p_valid),3))\n",
    "print('f1 =\\t', f1_dm_t)\n",
    "\n",
    "print('время предсказания модели составило', dt_dm_t,'секунд\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a2659",
   "metadata": {},
   "source": [
    "#### Соберем результаты вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "722aac91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>time_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.766</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression balanced</th>\n",
       "      <td>0.683</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.544</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier balanced</th>\n",
       "      <td>0.633</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default = toxic</th>\n",
       "      <td>0.186</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                f1  time_predict\n",
       "LogisticRegression           0.766         0.005\n",
       "LogisticRegression balanced  0.683         0.002\n",
       "LGBMClassifier               0.544         0.067\n",
       "LGBMClassifier balanced      0.633         0.052\n",
       "default = toxic              0.186         0.002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_dif_mod = pd.DataFrame(data = [[f1_lr   , dt_lr   ],\n",
    "                                      [f1_b_lr , dt_b_lr ],\n",
    "                                      [f1_lgb  , dt_lgb  ],\n",
    "                                      [f1_b_lgb, dt_b_lgb],\n",
    "                                      [f1_dm_t , dt_dm_t ]],\n",
    "                              \n",
    "                              columns = ['f1', 'time_predict'],\n",
    "                              \n",
    "                              index = ['LogisticRegression',\n",
    "                                       'LogisticRegression balanced',\n",
    "                                       'LGBMClassifier ',\n",
    "                                       'LGBMClassifier balanced',\n",
    "                                       'default = toxic'])\n",
    "\n",
    "display (result_dif_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1e8c8",
   "metadata": {},
   "source": [
    "С точки зрения максимизации  f1 лучше моделью является LogisticRegression, обученная на несбалансированой выборке.\n",
    "\n",
    "Рассчитаем значение метрики f1 на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e82b5e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "тестовая выборка\n",
      "f1 =\t 0.766\n",
      "время предсказания модели составило 0.005 сек\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression')\n",
    "print('тестовая выборка')\n",
    "\n",
    "model_lr.fit(f_train_idf, t_train)\n",
    "f1_lr, dt_lr = model_f1 (model_lr, f_test_idf, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3f151",
   "metadata": {},
   "source": [
    "###### 3. Выводы\n",
    "\n",
    "1. Исследованы исходные данные. Дубликаты, пропуски, не обнаружены, выборка является несбалансированной (около 10% сообщений являются негативными)\n",
    "2. Проведена подготовка исходных данных для обучения моделей\n",
    "3. Обучены модели LogisticRegression, LGBMClassifier, константная модель\n",
    "4. При обучении моделей на сбалансированной и несбалансированной выборке получены следующие значения метрики f1:\n",
    "   - для LogisticRegression значение f1 составило 0.766 и 0.683 для несбалансированной и сбалансированной выборки\n",
    "   - для LGBMClassifier значение f1 составило 0.544 и 0.633 для несбалансированной и сбалансированной выборки\n",
    "4. Лучшее значение метрики f1 достигнуто на моделе LogisticRegression, обученная на несбалансированой выборке. Значение f1 составило 0.766 на тестовой выборке. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e9b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 89,
    "start_time": "2023-07-12T21:04:06.591Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
